{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gonna start off with a whole bunch of imports; we can always get rid of ones \n",
    "# we don't need\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy.testing as npt\n",
    "from time import time\n",
    "import scipy.linalg as LA\n",
    "from numba import cuda\n",
    "#from simple_plot import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets start with attempting to get a parallel function to do value iteration for a small MDP and grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the ratio of a circle's circumference to its diameter, aka, three and a bit\n",
    "PI = np.pi\n",
    "# threads per block\n",
    "TPB = 8\n",
    "\n",
    "@cuda.jit(device = True)\n",
    "def d_isActionAllowed(x_curr, y_curr, action, nx, ny, wall_coords, term_coords):\n",
    "    \"\"\"\n",
    "    wall_coords is an n by 2 array of wall coordinate values\n",
    "    term_coords is an m by 2 array of terminal state coordinate values\n",
    "    \"\"\"\n",
    "    # initialize the isAllowed boolean to true: \n",
    "    isAllowed = True\n",
    "    x_new = -1\n",
    "    y_new = -1\n",
    "\n",
    "    if action == STAY:\n",
    "        x_new = x_curr\n",
    "        y_new = y_curr\n",
    "    elif action == UP:\n",
    "        x_new = x_curr\n",
    "        y_new = y_curr + 1\n",
    "    elif action == RIGHT:\n",
    "        x_new = x_curr + 1\n",
    "        y_new = y_curr\n",
    "    elif action == DOWN:\n",
    "        x_new = x_curr\n",
    "        y_new = y_curr -1\n",
    "    elif action == LEFT:\n",
    "        x_new = x_curr -1\n",
    "        y_new = y_curr\n",
    "\n",
    "    # first check to make sure the new move is in-bounds for the grid: \n",
    "    if x_new >= nx or x_new < 0 or y_new >= ny or y_new < 0:\n",
    "        isAllowed = False\n",
    "    \n",
    "    # then check to see if you're in a terminal state ...\n",
    "    isTerminal = False\n",
    "    for i in range(term_coords.shape[0]):\n",
    "        if term_coords[i, 0] == x_curr and term_coords[i, 1] == y_curr:\n",
    "            isTerminal = True\n",
    "    # the agent *must* stay if they are in a terminal state:\n",
    "    if action != STAY and isTerminal == True: \n",
    "        isAllowed = False\n",
    "    # the agent is not allowed to *choose* to stay unless they are in a terminal state: \n",
    "    elif action == STAY and isTerminal == False: \n",
    "        isAllowed = False\n",
    "\n",
    "    # then check to make sure your new move isn't into a wall: \n",
    "    for i in range(wall_coords.shape[0]):\n",
    "        if wall_coords[i, 0] == x_curr and wall_coords[i, 1] == y_curr:\n",
    "            isAllowed = False\n",
    "\n",
    "    return isAllowed\n",
    "\n",
    "#kernel accessing global memory array\n",
    "@cuda.jit\n",
    "def valueIteration_par_kernel(d_u, d_p, d_r, discount, nx, ny, d_wc, d_tc, parity):\n",
    "    \"\"\"\n",
    "    perform value iteration, i hope\n",
    "    \n",
    "    Arguments:\n",
    "        \n",
    "    returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    i, j = cuda.grid(2)\n",
    "    dims = d_u.shape\n",
    "\n",
    "    # return if we're out of bounds\n",
    "    if i >= (dims[0]) or j >= (dims[1]):\n",
    "        return\n",
    "\n",
    "    # return if we're in a terminal state: \n",
    "    for k in range(d_tc.shape[0]):\n",
    "        if d_tc[k, 0] == i and d_tc[k, 1] == j:\n",
    "            return\n",
    "    \n",
    "    # return if we're inside a wall: \n",
    "    #for m in range(d_wc.shape[0]):\n",
    "    #    if d_wc[m, 0] == i and d_wc[m, 1] == j:\n",
    "    #        return\n",
    "\n",
    "    # We define black squares as squares where i+j is even, and red squares \n",
    "    # as squares where i+j is odd. Furthermore, we define our parity such that black \n",
    "    # squares have parity == 0 while red squares have parity == 1.\n",
    "    # \n",
    "    # If (i+j)%2 == 1, then (i+j) is odd, so we're at a red square, so we should only \n",
    "    # calculate d_u[i, j] if parity == 1. Conversely, if (i+j)%2 == 0, then (i+j) is \n",
    "    # even, and we're at a black square, so we should only calculate d_u[i, j] if \n",
    "    # parity == 0. This simplifies down to the following if-statement: \n",
    "    if (i+j)%2 == parity:\n",
    "        maxQVal = -666420.0\n",
    "        for a in range(NUM_ACTIONS): \n",
    "            # begin calculation for current qValue ===========================\n",
    "            qValue = np.float32(0.0)\n",
    "            for sP in range(NUM_ACTIONS): \n",
    "                if d_isActionAllowed(i, j, a, nx, ny, d_wc, d_tc): \n",
    "                    # calculate the probability and reward for each action-\n",
    "                    # state_prime pair: \n",
    "                    uPrime = 0\n",
    "                    prob = d_p[i, j, a, sP]\n",
    "                    reward = d_r[i, j, a, sP]\n",
    "                    if sP == STAY:\n",
    "                        uPrime = d_u[i, j]\n",
    "                    elif sP == UP and j+1 < (dims[1]): \n",
    "                        uPrime = d_u[i, j+1]\n",
    "                    elif sP == DOWN and j-1 >= 0: \n",
    "                        uPrime = d_u[i, j-1]\n",
    "                    elif sP == LEFT and i-1 >= 0: \n",
    "                        uPrime = d_u[i-1, j]\n",
    "                    elif sP == RIGHT and i+1 < (dims[0]): \n",
    "                        uPrime = d_u[i+1, j]\n",
    "                    \n",
    "                    qValue += prob*(reward + discount*uPrime)\n",
    "            # end calculation for current qValue ===========================\n",
    "            curr_qVal = qValue\n",
    "            # determine if current qValue is the new maximum qValue: \n",
    "            if curr_qVal >= maxQVal:\n",
    "                maxQVal = curr_qVal\n",
    "        d_u[i, j] = maxQVal\n",
    "\n",
    "\n",
    "def valueIteration_par(u2, p2, r2, iters, discount, nx, ny, wall_coords, term_coords):\n",
    "    \"\"\"\n",
    "    Wrapper function for computing q-values\n",
    "    \n",
    "    Arguments:\n",
    "        u: numpy float 2D array of current values\n",
    "        iters: int number of update iterations\n",
    "    Returns:\n",
    "        updated 2D array of values\n",
    "    \"\"\"\n",
    "    start = cuda.event()\n",
    "    end = cuda.event()\n",
    " \n",
    "    wc_length = len(wall_coords)\n",
    "    wc = np.zeros(shape=[wc_length, 2], dtype = int)\n",
    "    i = 0\n",
    "    for wc_tuples in wall_coords:\n",
    "        wc[i, 0] = wc_tuples[0]\n",
    "        wc[i, 1] = wc_tuples[1]\n",
    "        i += 1\n",
    "    tc_length = len(term_coords)\n",
    "    tc = np.zeros(shape=[tc_length, 2], dtype = int)\n",
    "    j = 0\n",
    "    for tc_tuples in term_coords:\n",
    "        tc[j, 0] = tc_tuples[0]\n",
    "        tc[j, 1] = tc_tuples[1]\n",
    "        j += 1\n",
    "\n",
    "    d_u = cuda.to_device(u2)\n",
    "    d_p = cuda.to_device(p2)\n",
    "    d_r = cuda.to_device(r2)\n",
    "    d_wc = cuda.to_device(wc)\n",
    "    d_tc = cuda.to_device(tc)\n",
    "    dims = d_u.shape\n",
    "    gridDims = [(dims[0]+TPB-1)//TPB, (dims[1]+TPB-1)//TPB]\n",
    "    blockDims = [TPB, TPB]\n",
    "\n",
    "    start.record()\n",
    "    for k in range(iters):\n",
    "        valueIteration_par_kernel[gridDims, blockDims](d_u, d_p, d_r, discount, nx, ny, d_wc, d_tc, 0)\n",
    "        valueIteration_par_kernel[gridDims, blockDims](d_u, d_p, d_r, discount, nx, ny, d_wc, d_tc, 1)\n",
    "\n",
    "    end.record()\n",
    "    end.synchronize()\n",
    "    elapsed = cuda.event_elapsed_time(start, end)\n",
    "\n",
    "    return elapsed, d_u.copy_to_host()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valueIteration_ser(u, p, r, iterations, discount, nx, ny, wall_coords, term_coords):\n",
    "    dims = u.shape\n",
    "    nx = dims[0]\n",
    "    ny = dims[1]\n",
    "\n",
    "    u_new = np.copy(u)\n",
    "    \n",
    "    for n in range(iterations):\n",
    "        u_old = np.copy(u_new)\n",
    "        for i in range(nx):\n",
    "            for j in range(ny):\n",
    "                # we don't iterate for terminal states or inside of walls: \n",
    "                if ((i, j) in term_coords) == True or ((i, j) in wall_coords):\n",
    "                    continue\n",
    "                maxQVal = -666420.0 \n",
    "                for a in range(NUM_ACTIONS): \n",
    "                    # begin calculation for current qValue ===========================\n",
    "                    qValue = np.float32(0.0)\n",
    "                    for sP in range(NUM_ACTIONS): \n",
    "                        if isActionAllowed((i, j), a, nx, ny, wall_coords, term_coords): \n",
    "                            # calculate the probability and reward for each action-\n",
    "                            # state_prime pair: \n",
    "                            uPrime = np.float32(0.0)\n",
    "                            prob = p[i, j, a, sP]\n",
    "                            reward = r[i, j, a, sP]\n",
    "                            if sP == STAY:\n",
    "                                uPrime = u_old[i, j]\n",
    "                            elif sP == UP and j+1 < (dims[1]): \n",
    "                                uPrime = u_old[i, j+1]\n",
    "                            elif sP == DOWN and j-1 >= 0: \n",
    "                                uPrime = u_old[i, j-1]\n",
    "                            elif sP == LEFT and i-1 >= 0: \n",
    "                                uPrime = u_old[i-1, j]\n",
    "                            elif sP == RIGHT and i+1 < (dims[0]): \n",
    "                                uPrime = u_old[i+1, j]\n",
    "                            \n",
    "                            qValue += prob*(reward + discount*uPrime)\n",
    "                    # end calculation for current qValue ===========================\n",
    "                    curr_qVal = qValue\n",
    "                    # determine if current qValue is the new maximum qValue: \n",
    "                    if curr_qVal >= maxQVal:\n",
    "                        maxQVal = curr_qVal\n",
    "                u_new[i, j] = maxQVal\n",
    "    \n",
    "    return u_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isActionAllowed(curr_coords, action, nx, ny, wall_coords, term_coords):\n",
    "    \"\"\"\n",
    "    curr_coords is a tuple of ints (x_coord, y_coord)\n",
    "    wall_coords is a list of tuples of ints\n",
    "    \"\"\"\n",
    "    # initialize the isAllowed boolean to true: \n",
    "    isAllowed = True\n",
    "    x_curr = curr_coords[0]\n",
    "    y_curr = curr_coords[1]\n",
    "    x_new = -1\n",
    "    y_new = -1\n",
    "\n",
    "    if action == STAY:\n",
    "        x_new = x_curr\n",
    "        y_new = y_curr\n",
    "    elif action == UP:\n",
    "        x_new = x_curr\n",
    "        y_new = y_curr + 1\n",
    "    elif action == RIGHT:\n",
    "        x_new = x_curr + 1\n",
    "        y_new = y_curr\n",
    "    elif action == DOWN:\n",
    "        x_new = x_curr\n",
    "        y_new = y_curr -1\n",
    "    elif action == LEFT:\n",
    "        x_new = x_curr -1\n",
    "        y_new = y_curr\n",
    "\n",
    "    # first check to make sure the new move is in-bounds for the grid: \n",
    "    if x_new >= nx or x_new < 0 or y_new >= ny or y_new < 0:\n",
    "        isAllowed = False\n",
    "    \n",
    "    # then check to make sure you're not at a terminal state: \n",
    "    if (x_curr, y_curr) in term_coords and action != STAY: \n",
    "        isAllowed = False\n",
    "    \n",
    "    # the agent is not allowed to *choose* to stay unless they are in a terminal state: \n",
    "    if action == STAY and ((x_curr, y_curr) in term_coords) == False: \n",
    "        isAllowed = False\n",
    "\n",
    "    # then check to make sure your new move isn't into a wall: \n",
    "    if (x_new, y_new) in wall_coords: \n",
    "        isAllowed = False\n",
    "\n",
    "    return isAllowed\n",
    "\n",
    "# initialize the probability matrix (or is it a tensor?)\n",
    "def probSetup(nx, ny, term_coords, wall_coords, noise):\n",
    "    \"\"\"\n",
    "    takes nx, ny, coords for terminal states, the coordinates for interior walls, \n",
    "    noise, anything else? and returns p\n",
    "    \"\"\"\n",
    "    # the signal is 1 minus the noise: \n",
    "    signal = 1.0 - noise\n",
    "    # initialize the probability matrix to a bunch of zeros: \n",
    "    p_init = np.zeros(shape=[nx, ny, NUM_ACTIONS, sP_size], dtype = np.float32)\n",
    "\n",
    "    # loop through all of the x and y values: \n",
    "    for i in range(nx):\n",
    "        for j in range(ny):\n",
    "            # loop through all the action values: \n",
    "            for a in range(NUM_ACTIONS): \n",
    "                # These statements are important for edge cases, e.g.: if the agent tries \n",
    "                # to move up, but both up and, say, left are blocked, then there should \n",
    "                # be a 10% chance to move right, and a (80% plus 10% =) 90% chance to \n",
    "                # stay. The edge cases are dealt with in the mess of if-else statements \n",
    "                # in the rest of this loop.\n",
    "                upAllowed = isActionAllowed((i, j), UP, nx, ny, wall_coords, term_coords)\n",
    "                rightAllowed = isActionAllowed((i, j), RIGHT, nx, ny, wall_coords, term_coords)\n",
    "                downAllowed = isActionAllowed((i, j), DOWN, nx, ny, wall_coords, term_coords)\n",
    "                leftAllowed = isActionAllowed((i, j), LEFT, nx, ny, wall_coords, term_coords)\n",
    "\n",
    "                if isActionAllowed((i, j), a, nx, ny, wall_coords, term_coords): \n",
    "                    # this if-statement is only triggered for terminal states (the 'stay' \n",
    "                    # action is not allowed for non-terminal states): \n",
    "                    if a == 0: \n",
    "                        # the probability of staying/exiting when the action 'stay/exit' \n",
    "                        # is selected is always 1 for terminal states\n",
    "                        p_init[i, j, STAY, STAY] = 1.0\n",
    "\n",
    "                    # if you don't stay, then signal% chance of performing the action you take: \n",
    "                    p_init[i, j, a, a] = signal\n",
    "\n",
    "                    # if the action is left or right, then you have a [noise/2]% chance \n",
    "                    # to go up, and the same to go down: \n",
    "                    if a == LEFT or a == RIGHT:\n",
    "                        if upAllowed: \n",
    "                            p_init[i, j, a, UP] = noise/2.0\n",
    "                        else: \n",
    "                            # the '+=' here is b/c if the agent is in a corridor, then \n",
    "                            # the prob of STAY ends up being (noise/2) + (noise/2)\n",
    "                            p_init[i, j, a, STAY] += noise/2.0\n",
    "                        if downAllowed: \n",
    "                            p_init[i, j, a, DOWN] = noise/2.0\n",
    "                        else: \n",
    "                            p_init[i, j, a, STAY] += noise/2.0\n",
    "                    # if the action is up or down, then you have a [noise/2]% chance to \n",
    "                    # go left, and the same to go right: \n",
    "                    else: # the action\n",
    "                        if rightAllowed: \n",
    "                            p_init[i, j, a, RIGHT] = noise/2.0\n",
    "                        else: \n",
    "                            p_init[i, j, a, STAY] += noise/2.0\n",
    "                        if leftAllowed: \n",
    "                            p_init[i, j, a, LEFT] = noise/2.0\n",
    "                        else: \n",
    "                            p_init[i, j, a, STAY] += noise/2.0\n",
    "                # if !isActionAllowed, then we gotta update the STAY probabilities: \n",
    "                else: \n",
    "                    if a > 0: \n",
    "                        if a == LEFT or a == RIGHT:\n",
    "                            if upAllowed: \n",
    "                                p_init[i, j, a, UP] = noise/2.0\n",
    "                            else: \n",
    "                                p_init[i, j, a, STAY] += noise/2.0\n",
    "                            if downAllowed: \n",
    "                                p_init[i, j, a, DOWN] = noise/2.0\n",
    "                            else: \n",
    "                                p_init[i, j, a, STAY] += noise/2.0\n",
    "                            p_init[i, j, a, STAY] += signal\n",
    "                        # a == UP or a == DOWN: \n",
    "                        else: \n",
    "                            if rightAllowed: \n",
    "                                p_init[i, j, a, RIGHT] = noise/2.0\n",
    "                            else: \n",
    "                                p_init[i, j, a, STAY] += noise/2.0\n",
    "                            if leftAllowed: \n",
    "                                p_init[i, j, a, LEFT] = noise/2.0\n",
    "                            else: \n",
    "                                p_init[i, j, a, STAY] += noise/2.0\n",
    "                            p_init[i, j, a, STAY] += signal\n",
    "    \n",
    "    return p_init\n",
    "                \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serial_elapsed = 1625.3669016361237 seconds\n",
      "parallel_elapsed = 4.88345703125 seconds\n"
     ]
    }
   ],
   "source": [
    "# here we're gonna set up the MDP and grid:\n",
    "nx, ny = 100, 100\n",
    "# the actions are: 0 = stay/exit, 1 = up, 2 = right, 3 = down, 4 = left. Note that up and \n",
    "# down are odd, while left and right are even; this is convenient because an odd action \n",
    "# has a [noise]% chance of taking an even action, and vice versa\n",
    "STAY = 0\n",
    "UP = 1\n",
    "RIGHT = 2\n",
    "DOWN = 3\n",
    "LEFT = 4\n",
    "NUM_ACTIONS = 5 \n",
    "sP_size = 5 \n",
    "iters = 500\n",
    "discount = np.float32(0.9)\n",
    "# probability of performing the action you're attempting to perform: \n",
    "signal = 0.8\n",
    "# probability of doing not that: \n",
    "noise = 1.0 - signal\n",
    "\n",
    "# initialize \n",
    "term_coords = [(nx-1, ny-1), (0, ny-1)]\n",
    "wall_coords = [(-1, -1)]\n",
    "# lets have a bunch of equally spaced walls, just to make things spicy\n",
    "for i in range(nx):\n",
    "    for j in range(ny):\n",
    "        if i%3 == 0 and j %3 == 0 and ((i, j) in term_coords) == False: \n",
    "            wall_coords.append((i, j))\n",
    "\n",
    "p_init = probSetup(nx, ny, term_coords, wall_coords, noise)\n",
    "u_init = np.zeros(shape=[nx, ny], dtype = np.float32)\n",
    "r_init = np.zeros(shape=[nx, ny, NUM_ACTIONS, sP_size], dtype = np.float32)\n",
    "\n",
    "for i in range(nx):\n",
    "    for j in range(ny):\n",
    "        for a in range(NUM_ACTIONS): \n",
    "            for b in range(NUM_ACTIONS):\n",
    "                # for basic bitch grid, all actions (except STAY in a terminal state) \n",
    "                # have a reward of WHATEVER I WANT (they have a reward of zero and a \n",
    "                # discount of 0.9 in order to be consistent with the Berkeley pacman \n",
    "                # AI projects): \n",
    "                r_init[i, j, a, b] = 0.0\n",
    "\n",
    "# now we take care of the terminal states; first, we give the reward for staying in a \n",
    "# terminal state, as well as the u value for the terminal states: \n",
    "u_init[nx-1, ny-1] = -20.0\n",
    "u_init[0, ny-1] = 20.0\n",
    "r_init[nx-1, ny-1, STAY, STAY] = -20.0\n",
    "r_init[0, ny-1, STAY, STAY] = 20.0\n",
    "\n",
    "# we gotta copy the initial matrices and send the copies to the valueIteration functions \n",
    "# so that the initial matrices don't get altered \n",
    "u1 = np.copy(u_init)\n",
    "p1 = np.copy(p_init)\n",
    "r1 = np.copy(r_init)\n",
    "start = time()\n",
    "u_ser = valueIteration_ser(u1, p1, r1, iters, discount, nx, ny, wall_coords, term_coords)\n",
    "stop = time()\n",
    "serial_elapsed = stop - start\n",
    "\n",
    "u2 = np.copy(u_init)\n",
    "p2 = np.copy(p_init)\n",
    "r2 = np.copy(r_init)\n",
    "parallel_elapsed, u_par = valueIteration_par(u2, p2, r2, iters, discount, nx, ny, wall_coords, term_coords)\n",
    "\n",
    "print(\"serial_elapsed =\", serial_elapsed, \"seconds\")\n",
    "print(\"parallel_elapsed =\", parallel_elapsed/1000, \"seconds\")\n",
    "\n",
    "npt.assert_allclose(u_ser, u_par, atol = 1e-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d62b51597be18f93944234ad292c57717caf7c6510d2cf4ef79736ceb572ac63"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
